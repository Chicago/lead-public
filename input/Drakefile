import_shapefile()
        BASENAME=$(echo $INPUT | sed 's/.shp//')
        # get table name from output, e.g. change $BASE/psql/input/wards gives input.wards
        TABLENAME=$(echo $OUTPUT | sed 's/.*psql\///;s/\//./')
        # ogr2ogr doesn't like an existing file
        rm -f "$BASENAME"4326.*
        ogr2ogr -t_srs EPSG:4326 "$BASENAME"4326.shp $INPUT
        # -q suppresses query output which for large shapefiles seems to slow down the import
        shp2pgsql -I -D -d -s 4326 "$BASENAME"4326.shp $TABLENAME | psql -q
        touch $OUTPUT

wget_unzip()
    mkdir -p $(dirname $OUTPUT0)
    wget --output-document="$OUTPUT0" "$URL"
    unzip -o "$OUTPUT0" -d $(dirname $OUTPUT1)

; wards
URL="https://data.cityofchicago.org/api/geospatial/sp34-6z76?method=export&format=Shapefile"
data/shapefiles/wards.zip, data/shapefiles/wards/WARDS_2015.shp <- [-timecheck method:wget_unzip]
psql/input/wards <- data/shapefiles/wards/WARDS_2015.shp [method:import_shapefile]

; census tracts
URL="https://data.cityofchicago.org/api/geospatial/5jrd-6zik?method=export&format=Shapefile"
data/shapefiles/census_tracts.zip, data/shapefiles/census_tracts/CensusTractsTIGER2010.shp <- [-timecheck method:wget_unzip]
psql/input/census_tracts <- data/shapefiles/census_tracts/CensusTractsTIGER2010.shp [method:import_shapefile]
	
; addresses
URL="https://datacatalog.cookcountyil.gov/api/geospatial/jev2-4wjs?method=export&format=Shapefile"
data/shapefiles/addresses.zip, data/shapefiles/addresses/addressPointChi.shp <- [-timecheck method:wget_unzip]
psql/input/addresses <- data/shapefiles/addresses/addressPointChi.shp [method:import_shapefile]

; community areas
URL="https://data.cityofchicago.org/api/geospatial/cauq-8yn6?method=export&format=Shapefile"
data/shapefiles/community_areas.zip, data/shapefiles/community_areas/CommAreas.shp <- [-timecheck method:wget_unzip]
psql/input/community_areas <- data/shapefiles/community_areas/CommAreas.shp [method:import_shapefile]

; census blocks
URL="https://data.cityofchicago.org/api/geospatial/mfzt-js4n?method=export&format=Shapefile"
data/shapefiles/census_blocks.zip, data/shapefiles/census_blocks/CensusBlockTIGER2010.shp <- [-timecheck method:wget_unzip]
psql/input/census_blocks <- data/shapefiles/census_blocks/CensusBlockTIGER2010.shp [method:import_shapefile]

; assessor 
psql/input/assessor <- input/assessor.sh
    $INPUT $ASSESSOR_FILE && touch $OUTPUT

; old blood tests, $[M7_FILE]
psql/input/m7 <- input/m7.sh
	$INPUT $INPUT1 && touch $OUTPUT

; current blood tests
psql/input/currbllshort <- input/currbllshort.sh, $[CURRBLLSHORT_FILE]
    $INPUT $INPUT1 && touch $OUTPUT

; inspections
psql/input/inspections <- input/inspections.sh
	$INPUT $INSPECTIONS_FILE && touch $OUTPUT

; census surname ethnicity
; documentation: http://www2.census.gov/topics/genealogy/2000surnames/surnames.pdf
data/surnames/names.zip <- [-timecheck]
	mkdir -p `dirname $OUTPUT`
	wget -O $OUTPUT http://www2.census.gov/topics/genealogy/2000surnames/names.zip

data/surnames/app_c.csv <- data/surnames/names.zip
	unzip -o $INPUT -d `dirname $OUTPUT` && touch $OUTPUT # update timestamp

; remove suprressed values
data/surnames/surnames.csv <- data/surnames/app_c.csv
     cat $INPUT | sed 's/(S)/0/g' > $OUTPUT

psql/input/surnames <- input/surnames.sql, data/surnames/surnames.csv [method:psql]

; download, unzip, and import buildings data
data/shapefiles/buildings/data/Buildings.zip <- [-timecheck]
    git clone https://github.com/Chicago/osd-building-footprints $(dirname $(dirname $OUTPUT))

data/shapefiles/buildings/data/Buildings.json <- data/shapefiles/buildings/data/Buildings.zip [-timecheck]
    unzip $INPUT -d $(dirname $OUTPUT)

psql/input/buildings <- input/buildings.sh, data/shapefiles/buildings/data/Buildings.json
    $INPUT $INPUT1 && touch $OUTPUT

; download and import building permit data
data/building_permits.csv <- [-timecheck]
	wget -O- "https://data.cityofchicago.org/api/views/ydr8-5enu/rows.csv?accessType=DOWNLOAD" | sed 's/\$//g' > $OUTPUT
psql/input/building_permits <- input/building_permits.sql, data/building_permits.csv [method:psql]

; download and import building violations data
data/building_violations.csv <- [-timecheck]
	wget -O- "https://data.cityofchicago.org/api/views/22u3-xenr/rows.csv?accessType=DOWNLOAD" | sed 's/, ,/,,/g' > $OUTPUT
psql/input/building_violations <- input/building_violations.sql, data/building_violations.csv [method:psql]

; American Community Survey data gets imported into its own db
%include $[ACS_PROFILE]

data/census-postgres/ <- [-timecheck]
     git clone https://github.com/censusreporter/census-postgres.git $OUTPUT

$(for y in {2009..2014}; do

echo "URL=\"http://www2.census.gov/programs-surveys/acs/summary_file/"$y"/data/5_year_by_state/Illinois_Tracts_Block_Groups_Only.zip\""
echo "data/acs/acs"$y"_5yr.zip, data/acs/acs"$y"_5yr/g"$y"5il.txt <- [-timecheck method:wget_unzip]"

echo "input/acs/generated/acs"$y"_5yr/import.sql <- input/acs/census_postgres.sh, data/census-postgres/"
echo "    \$INPUT0 \$INPUT1/acs"$y"_5yr/ data/acs/acs"$y"_5yr/ input/acs/generated/acs"$y"_5yr/"

echo "psql/acs"$y"_5yr <- input/acs/generated/acs"$y"_5yr/import.sql, data/acs/acs"$y"_5yr/g"$y"5il.txt [method:psql]"

done)

; selected acs variables copied to lead db via csv
data/acs.csv <- input/acs/download.py, psql/acs2009_5yr, psql/acs2010_5yr, psql/acs2011_5yr, psql/acs2012_5yr, psql/acs2013_5yr
    $INPUT $OUTPUT

%include $[PROFILE]
psql/input/acs <- input/acs/import.py, data/acs.csv
    $INPUT $INPUT1 && touch $OUTPUT

; Cornerstone WIC data
psql/cornerstone/ <- [method:psql_schema -timecheck]

$(for table in Partaddr PartPgm PartEnrl Prenatl Birth; do

echo "psql/cornerstone/"$table" <- \$[CORNERSTONE_DIR]/"$table".dbf"
echo "    ogr2ogr -f PostgreSQL PG:'host=\$[PGHOST] user=\$[PGUSER] password=\$[PGPASSWORD] dbname=\$[PGDATABASE]' \$INPUT -lco 'schema=cornerstone' -lco 'overwrite=yes' && touch \$OUTPUT"

done)

data/Partaddr.csv <- $[CORNERSTONE_DIR]/Partaddr.dbf, input/dbf2csv.py
    python $INPUT1 $INPUT0 > $OUTPUT

; ogr2ogr for Partaddr only creates table but does not load data! so \copy data with dbf2csv
psql/cornerstone/Partaddr2 <- $[CORNERSTONE_DIR]/Partaddr.dbf, psql/cornerstone/Partaddr, input/dbf2csv.py
    psql -v ON_ERROR_STOP=1 -c 'alter table cornerstone.partaddr drop column ogc_fid'
    python $INPUT2 $INPUT0 | psql -v ON_ERROR_STOP=1 -c '\copy cornerstone.partaddr from STDIN with csv header'
    psql -v ON_ERROR_STOP=1 -c 'alter table cornerstone.partaddr add column ogc_fid serial primary key'
    touch $OUTPUT

data/cornerstone/addresses_for_geocoding.csv <- input/cornerstone/addresses_for_geocoding.sql, psql/cornerstone/Partaddr2
    psql -f $INPUT > $OUTPUT

; unique cornerstone addresses geocoded using city geocoder
psql/cornerstone/addresses <- input/cornerstone/addresses.sh, $[CORNERSTONE_ADDRESSES_FILE]
    $INPUT0 $INPUT1 && touch $OUTPUT
